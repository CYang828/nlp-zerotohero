{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9TnJztDZGw-n",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 使用 RNN 做文本分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lUWearf0Gw-p",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "文本分类任务使用 [recurrent neural network](https://developers.google.com/machine-learning/glossary/#recurrent_neural_network) 在 [IMDB large movie review dataset](http://ai.stanford.edu/~amaas/data/sentiment/) 数据机上训练情感分类任务。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 安装依赖\n",
    "\n",
    "先来安装需要用到的依赖包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy tensorflow_datasets tensorflow -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2VQo4bajwUU",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 导入依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z682XYsrjkY9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "tfds.disable_progress_bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1rXHa-w9JZhb",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "导入  `matplotlib` 并且创建一个帮主函数来画图:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mp1Z7P9pYRSK",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_graphs(history, metric):\n",
    "    plt.plot(history.history[metric])\n",
    "    plt.plot(history.history[\"val_\" + metric], \"\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([metric, \"val_\" + metric])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pRmMubr0jrE2",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 创建输入 Pipeline\n",
    "\n",
    "IMDB 数据集是一个二分类的数据集，其中包含的评论信息有两种分类 *positive* 和 *negative* 的情感。\n",
    "\n",
    "使用 [TFDS](https://www.tensorflow.org/datasets) 下载数据集. 查看 [loading text tutorial](https://www.tensorflow.org/tutorials/load_data/text) 查看如何手动的家在数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SHRwRoP2nVHX",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset, info = tfds.load(\"imdb_reviews\", with_info=True, as_supervised=True)\n",
    "train_dataset, test_dataset = dataset[\"train\"], dataset[\"test\"]\n",
    "\n",
    "train_dataset.element_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nWA4c2ir7g6p",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "这会返回 dataset 中的数据 (text, label pairs):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vd4_BGKyurao",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for example, label in train_dataset.take(1):\n",
    "    print(\"text: \", example.numpy())\n",
    "    print(\"label: \", label.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z2qVJzcEluH_",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "接下来，把训练集数据打乱并且创建批量的 `(text, label)` 对:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dDsCaZCDYZgm",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VznrltNOnUc5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = (\n",
    "    train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jqkvdcFv41wC",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for example, label in train_dataset.take(1):\n",
    "    print(\"texts: \", example.numpy()[:3])\n",
    "    print()\n",
    "    print(\"labels: \", label.numpy()[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s5eWCo88voPY",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 创建文本编码器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TFevcItw15P_",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "在把数据输入到模型之前，我们需要先对数据进行预处理。最简单的去进行预处理的方法是使用 `TextVectorization` 层。\n",
    "\n",
    "创建层并且把数据集中的文本传入到这个层，使用 `.adapt` 函数进行计算:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uC25Lu1Yvuqy",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 1000\n",
    "encoder = tf.keras.layers.TextVectorization(max_tokens=VOCAB_SIZE)\n",
    "encoder.adapt(train_dataset.map(lambda text, label: text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IuQzVBbe3Ldu",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "`.adapt` 函数设置 Tokenization 层的词典，这里我们打印前20个 token。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tBoyjjWg0Ac9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "vocab = np.array(encoder.get_vocabulary())\n",
    "vocab[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mjId5pua3jHQ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "一旦我们有了词典，接下来就可以使用它把 tokens 转换成 indices（字典索引）。字典索引的张量会进行 padding，使用 0 把每一个 batch 中的数据补齐成最长的长度（除非设置一个固定的 `output_sequence_length`）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RGc7C9WiwRWs",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "encoded_example = encoder(example)[:3].numpy()\n",
    "encoded_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N_tD0QY5wXaK",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for n in range(3):\n",
    "    print(\"Original: \", example[n].numpy())\n",
    "    print(\"Round-trip: \", \" \".join(vocab[encoded_example[n]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bjUqGVBxGw-t",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 创建模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W7zsmInBOCPO",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "![A drawing of the information flow in the model](../images/bidirectional.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bgs6nnSTGw-t",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "上面的图片是模型的结构：\n",
    "\n",
    "1. 这个模型可以使用 `tf.keras.Sequential` 进行构建。\n",
    "\n",
    "2. 第一层是 `encoder`，把文本转换为字典索引的序列。\n",
    "\n",
    "3. 在 `encoder` 之后是一个 embedding 层。embedding 层中保存的是每一个单词的向量。一旦我们调用它，它会把这个索引序列转换为向量的序列。 这些向量是一些可以被训练的向量。通过足够数据的训练，这些向量会学习到语义的信息。\n",
    "\n",
    "4. RNN 网络结构能够处理上面处理过的向量序列。按照时间步骤，它能够一个个的进行处理。\n",
    "\n",
    "  `tf.keras.layers.Bidirectional` wrapper 也可以被使用。 它可以从反方向捕获语义信息，最终我们把正向的语义输出和反向语义输出 concatenates 到一起，得到最终的语义输出。\n",
    "\n",
    "  * bidirectional RNN 的主要优势是能够捕获正向和反向的文本语义。\n",
    "\n",
    "  * 主要的缺点是，这样做需要同时捕获正向和反向的语义，效率很低。\n",
    "\n",
    "5. 在 RNN 之后，我们使用两层 `layers.Dense` 把序列转化为一个向量，这个向量作为最终的分类 logit。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V4fodCI7soQi",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "按照上述结构实现如下:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LwfoBkmRYcP3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        encoder,\n",
    "        tf.keras.layers.Embedding(\n",
    "            input_dim=len(encoder.get_vocabulary()),\n",
    "            output_dim=64,\n",
    "            # Use masking to handle the variable sequence lengths\n",
    "            mask_zero=True,\n",
    "        ),\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(1),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QIGmIGkkouUb",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "请注意，这里使用的是Keras序列模型，因为模型中的所有层都只有一个输入并产生单个输出。如果您想使用有状态的RNN层，您可能希望使用Keras函数API或模型子类化构建模型，以便检索和重用RNN层状态。请查看[Keras RNN指南](https://www.tensorflow.org/guide/keras/rnn#rnn_state_reuse)更多细节。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kF-PsCk1LwjY",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "嵌入层[use mask](https://www.tensorflow.org/guide/keras/masking_and_padding)以处理变化的序列长度。“嵌入”支持掩蔽后的所有层："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "87a8-CwfKebw",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print([layer.supports_masking for layer in model.layers])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZlS0iaUIWLpI",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "为了证实这一点，请对一个句子进行两次评估。首先，单独使用，这样就没有填充来屏蔽："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O41gw3KfWHus",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# predict on a sample text without padding.\n",
    "\n",
    "sample_text = (\n",
    "    \"The movie was cool. The animation and the graphics \"\n",
    "    \"were out of this world. I would recommend this movie.\"\n",
    ")\n",
    "predictions = model.predict(np.array([sample_text]))\n",
    "print(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K0VQmGnEWcuz",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "现在，用一个较长的句子在一批中再次评估它。结果应相同："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UIgpuTeFNDzq",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# predict on a sample text with padding\n",
    "\n",
    "padding = \"the \" * 2000\n",
    "predictions = model.predict(np.array([sample_text, padding]))\n",
    "print(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sRI776ZcH3Tf",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "编译Keras模型以配置培训过程："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kj2xei41YZjC",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zIwH3nto596k",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hw86wWS4YgR2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_dataset, epochs=10, validation_data=test_dataset, validation_steps=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BaNbXi43YgUT",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OZmwt_mzaQJk",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_graphs(history, \"accuracy\")\n",
    "plt.ylim(None, 1)\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_graphs(history, \"loss\")\n",
    "plt.ylim(0, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DwSE_386uhxD",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "在新的句子上预测:\n",
    "\n",
    "如果预测 >= 0.0 则是 positive，否则就是 negative。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZXgfQSgRW6zU",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sample_text = (\n",
    "    \"The movie was cool. The animation and the graphics \"\n",
    "    \"were out of this world. I would recommend this movie.\"\n",
    ")\n",
    "predictions = model.predict(np.array([sample_text]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7g1evcaRpTKm",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 堆叠两层或者更多的 LSTM 层\n",
    "\n",
    "Keras递归层有两种可用模式，由 “return_sequences” 构造函数参数控制：\n",
    "\n",
    "* 如果“False”，则只返回每个输入序列的最后一个输出（形状的二维张量（batch_size，output_features））。这是先前模型中使用的默认值。\n",
    "\n",
    "* 如果“True”，则返回每个时间步的连续输出的完整序列（形状为“batch_size，timesteps，output_features”）的三维张量。\n",
    "\n",
    "下面是“return_sequences=True”的信息流：\n",
    "\n",
    "![layered_bidirectional](../images/layered_bidirectional.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wbSClCrG1z8l",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "使用带有“return_sequences=True”的“RNN”的有趣之处在于，输出仍然有3个轴，就像输入一样，因此可以传递到另一个RNN层，如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jo1jjO3vn0jo",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        encoder,\n",
    "        tf.keras.layers.Embedding(len(encoder.get_vocabulary()), 64, mask_zero=True),\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(1),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hEPV5jVGp-is",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LeSE-YjdqAeN",
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_dataset, epochs=10, validation_data=test_dataset, validation_steps=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_LdwilM1qPM3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ykUKnAoqbycW",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# predict on a sample text without padding.\n",
    "\n",
    "sample_text = (\n",
    "    \"The movie was not good. The animation and the graphics \"\n",
    "    \"were terrible. I would not recommend this movie.\"\n",
    ")\n",
    "predictions = model.predict(np.array([sample_text]))\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_YYub0EDtwCu",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_graphs(history, \"accuracy\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_graphs(history, \"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9xvpE3BaGw_V",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "查看其他现有的递归层，例如[GRU层](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRU)."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "text_classification_rnn.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "5b84fa068cbe281c83b6c92f858df5ddecef6cfd20c9809cc99112d874d08365"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
