{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rl0y0i2miQ-g"
   },
   "source": [
    " \n",
    " # [动手练习] NLP Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oaZe47L3iQ-l"
   },
   "source": [
    ":::{note} NLP Pipelines 可能存在变化\n",
    "\n",
    "- NLP 的处理流程不总是线性的\n",
    "- 经常在处理过程中会有循环\n",
    "- 这些任务都要具体的根据特定得任务来思考设计\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tXzi_tJTiQ-l"
   },
   "source": [
    "## 数据收集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DqatAID-iQ-l"
   },
   "source": [
    "### 数据采集 (Data Acquisition): 整个 ML 系统的核心\n",
    "\n",
    "- 理想的情况： 我们有所有想要的数据\n",
    "- 包括标签和注释\n",
    "- 但是，更现实的情况是，我们经常要处理的并不是理想情况，而是缺少各种数据的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jZFcHw3RiQ-m"
   },
   "source": [
    "### 不理想的情况的处理\n",
    "\n",
    "- 带有有限注释/标签的初始数据集\n",
    "- 基于正则表达式或启发式标记的初始数据集\n",
    "- 公共数据集 (cf. [Google Dataset Search](https://datasetsearch.research.google.com/) or [kaggle](https://www.kaggle.com/))\n",
    "- 不完整的数据\n",
    "- 产品上的干预\n",
    "- 数据增强"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3gQ5KXvaiQ-m"
   },
   "source": [
    "### 数据增强\n",
    "\n",
    "- 这是一种利用语言相似性来生产新数据的技术。\n",
    "- 常见的策略包括:\n",
    "    - 同义词替换 (synonym replacement)\n",
    "    - 相关词替换 (based on association metrics)\n",
    "    - 回译 (Back translation)\n",
    "    - 替换实体 (Replacing entities)\n",
    "    - 增加噪音 (e.g. spelling errors, random words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4xdlt9U-iQ-n"
   },
   "source": [
    "## 文本抽取和清理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Diq2nst3iQ-n"
   },
   "source": [
    "### 文本抽取\n",
    "\n",
    "- 从原始文本中抽取数据\n",
    "    - HTML\n",
    "    - PDF\n",
    "- 相关 vs. 非相关信息\n",
    "    - 非语义信息 (non-textual information)\n",
    "    - 标签 (markup)\n",
    "    - 元数据 (metadata)\n",
    "- 编码格式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rlnuEXD_iQ-o"
   },
   "source": [
    "#### 从网页中提取文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "gewVKa5wiQ-o",
    "outputId": "594dbc59-a1ca-4aa5-aed8-3d1784ed18ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://news.google.com/articles/CBMiPmh0dHA6Ly9wb2xpdGljcy5wZW9wbGUuY29tLmNuL24xLzIwMjIvMDgyNC9jMTAwMS0zMjUxMDA4Ny5odG1s0gEA?hl=zh-CN&gl=CN&ceid=CN%3Azh-Hans\n",
      "b''\n",
      "b'\\n\\t\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xc7\\xb0\\xc8\\xab\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xd1\\xb4\\xef\\xbf\\xbd\\xe9\\xba\\xb5\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xd3\\xa3\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xd1\\xb4\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xd4\\xb4\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xda\\xb9\\xd8\\xbc\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xda\\xa3\\xef\\xbf\\xbd\\xcf\\xb0\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xc6\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xc7\\xb6\\xef\\xbf\\xbd\\xce\\xbe\\xcd\\xb7\\xef\\xbf\\xbd\\xd1\\xb4\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xd6\\xb9\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xd2\\xaa\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd'\n",
      "b'\\n\\t\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xca\\xae\\xef\\xbf\\xbd\\xcb\\xb4\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xda\\xb7\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xd6\\xbc\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xd6\\xbe\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xd6\\xb9\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xc7\\xa1\\xef\\xbf\\xbd\\xca\\xb1\\xca\\xb1\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xc4\\xb2\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xc2\\xa1\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xda\\xb6\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xc8\\xab\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xce\\xbb\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xd1\\xb4\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xd6\\xb9\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd+\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xdf\\xa2\\xc8\\xa1\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xd2\\xaa\\xd6\\xb8\\xca\\xbe\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xd2\\xbb\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xd1\\xa7\\xcf\\xb0\\xef\\xbf\\xbd\\xef\\xbf\\xbd'\n",
      "b'\\n'\n",
      "b'\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xc3\\xb8\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xcb\\xbf\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd  '\n",
      "b'\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xd5\\xb1\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xc5\\xbf\\xef\\xbf\\xbd\\n|\\n\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\n|\\n\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xc6\\xb8\\n|\\n\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xc6\\xb8\\xd3\\xa2\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\n|\\n\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\n|\\n\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\n|\\n\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\n|\\n\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xdd\\xb7\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\n|\\n\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xd5\\xbe\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\n|\\n\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xd5\\xbe\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xca\\xa6\\n|\\n\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xcf\\xa2\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\n|\\n\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xcf\\xb5\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\n'\n",
      "b'\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xd5\\xb1\\xef\\xbf\\xbd\\xce\\xa5\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xcd\\xb2\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xcf\\xa2\\xef\\xbf\\xbd\\xd9\\xb1\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xe7\\xbb\\xb0\\xef\\xbf\\xbd\\xef\\xbf\\xbd010-65363263\\xc2\\xa0\\xc2\\xa0\\xc2\\xa0\\xc2\\xa0\\xef\\xbf\\xbd\\xd9\\xb1\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xe4\\xa3\\xbajubao@people.cn'\n",
      "b'\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xe4\\xa3\\xbakf@people.cn\\xc2\\xa0\\xc2\\xa0\\xc2\\xa0\\xc2\\xa0\\xce\\xa5\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xcd\\xb2\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xcf\\xa2\\xef\\xbf\\xbd\\xd9\\xb1\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xe7\\xbb\\xb0\\xef\\xbf\\xbd\\xef\\xbf\\xbd010-65363636\\xc2\\xa0\\xc2\\xa0\\xc2\\xa0\\xc2\\xa0\\xef\\xbf\\xbd\\xd9\\xb1\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xe4\\xa3\\xbarmwjubao@people.cn'\n",
      "b'\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xcf\\xa2\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xd6\\xa410120170001\\xc2\\xa0\\xc2\\xa0|\\xc2\\xa0\\xc2\\xa0\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xd6\\xb5\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xd2\\xb5\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xd3\\xaa\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xd6\\xa4B1-20060139\\xc2\\xa0\\xc2\\xa0|\\xc2\\xa0\\xc2\\xa0\\xef\\xbf\\xbd\\xe3\\xb2\\xa5\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xd3\\xbd\\xef\\xbf\\xbd\\xc4\\xbf\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xd3\\xaa\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xd6\\xa4\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xc3\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xd6\\xb5\\xef\\xbf\\xbd172\\xef\\xbf\\xbd\\xef\\xbf\\xbd'\n",
      "b'\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xcf\\xa2\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xe7\\xb4\\xab\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xc4\\xbf\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xd6\\xa40104065\\xc2\\xa0|\\xc2\\xa0\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xc4\\xbb\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xd3\\xaa\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xd6\\xa4 \\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd[2020]5494-1075\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xc2\\xa0|\\xc2\\xa0\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xd6\\xa4\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd121\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xc2\\xa0|\\xc2\\xa0\\xef\\xbf\\xbd\\xef\\xbf\\xbdICP\\xd6\\xa4000006\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xc2\\xa0|\\xc2\\xa0\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd11000002000008\\xef\\xbf\\xbd\\xef\\xbf\\xbd'\n",
      "b'\\n\\xef\\xbf\\xbd\\xef\\xbf\\xbd \\xef\\xbf\\xbd\\xef\\xbf\\xbd \\xef\\xbf\\xbd\\xef\\xbf\\xbd \\xef\\xbf\\xbd\\xef\\xbf\\xbd \\xc8\\xa8 \\xef\\xbf\\xbd\\xef\\xbf\\xbd \\xef\\xbf\\xbd\\xef\\xbf\\xbd \\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xce\\xb4 \\xef\\xbf\\xbd\\xef\\xbf\\xbd \\xef\\xbf\\xbd\\xef\\xbf\\xbd \\xef\\xbf\\xbd\\xef\\xbf\\xbd \\xef\\xbf\\xbd\\xef\\xbf\\xbd \\xc8\\xa8 \\xef\\xbf\\xbd\\xef\\xbf\\xbd \\xd6\\xb9 \\xca\\xb9 \\xef\\xbf\\xbd\\xef\\xbf\\xbd\\nCopyright \\xc2\\xa9 1997-2022 by www.people.com.cn. all rights reserved\\n'\n",
      "b'\\n\\n\\n\\n\\n\\n\\n'\n"
     ]
    }
   ],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import json\n",
    " \n",
    " \n",
    "url = 'https://news.google.com/topstories?hl=zh-CN&gl=CN&ceid=CN:zh-Hans'\n",
    "r = requests.get(url)\n",
    "web_content = r.text\n",
    "soup = BeautifulSoup(web_content,'html.parser')\n",
    "title = soup.find_all('a', class_='DY5T1d')\n",
    "first_art_link = title[1]['href'].replace('.','https://news.google.com',1)\n",
    "\n",
    "print(first_art_link)\n",
    "art_request = requests.get(first_art_link)\n",
    "art_request.encoding='utf8'\n",
    "soup_art = BeautifulSoup(art_request.text,'html.parser')\n",
    "\n",
    "art_content = soup_art.find_all('p')\n",
    "art_texts = [p.text for p in art_content]\n",
    "for text in art_texts:\n",
    "    print(text.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rD9mogK3iQ-q"
   },
   "source": [
    "#### 从扫描的 PDF 中提取文本\n",
    "\n",
    "需要安装 OCR 提取工具 tesseract，安装教程见 https://nanonets.com/blog/ocr-with-tesseract/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytesseract\n",
      "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in /Users/zhangchunyang/opt/anaconda3/envs/nlp/lib/python3.8/site-packages (from pytesseract) (21.3)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in /Users/zhangchunyang/opt/anaconda3/envs/nlp/lib/python3.8/site-packages (from pytesseract) (9.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/zhangchunyang/opt/anaconda3/envs/nlp/lib/python3.8/site-packages (from packaging>=21.3->pytesseract) (3.0.9)\n",
      "Installing collected packages: pytesseract\n",
      "Successfully installed pytesseract-0.3.10\n"
     ]
    }
   ],
   "source": [
    "!pip install pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "ypZR_UF9iQ-q",
    "outputId": "9cf587e6-aefa-4449-a888-12f79339864c",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TesseractNotFoundError",
     "evalue": "tesseract is not installed or it's not in your PATH. See README file for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp/lib/python3.8/site-packages/pytesseract/pytesseract.py:255\u001b[0m, in \u001b[0;36mrun_tesseract\u001b[0;34m(input_filename, output_filename_base, extension, lang, config, nice, timeout)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 255\u001b[0m     proc \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msubprocess_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp/lib/python3.8/subprocess.py:858\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[1;32m    856\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m--> 858\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp/lib/python3.8/subprocess.py:1704\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1703\u001b[0m         err_msg \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstrerror(errno_num)\n\u001b[0;32m-> 1704\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1705\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(err_msg)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'tesseract'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTesseractNotFoundError\u001b[0m                    Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m YOUR_DEMO_DATA_PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# please change your file path\u001b[39;00m\n\u001b[1;32m      6\u001b[0m filename \u001b[38;5;241m=\u001b[39m YOUR_DEMO_DATA_PATH\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpdf-firth-text.png\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 7\u001b[0m text \u001b[38;5;241m=\u001b[39m image_to_string(Image\u001b[38;5;241m.\u001b[39mopen(filename))\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(text)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp/lib/python3.8/site-packages/pytesseract/pytesseract.py:423\u001b[0m, in \u001b[0;36mimage_to_string\u001b[0;34m(image, lang, config, nice, output_type, timeout)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;124;03mReturns the result of a Tesseract OCR run on the provided image to string\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    421\u001b[0m args \u001b[38;5;241m=\u001b[39m [image, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtxt\u001b[39m\u001b[38;5;124m'\u001b[39m, lang, config, nice, timeout]\n\u001b[0;32m--> 423\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m{\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mOutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBYTES\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m    \u001b[49m\u001b[43mOutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDICT\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m    \u001b[49m\u001b[43mOutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSTRING\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m\u001b[49m\u001b[43m}\u001b[49m\u001b[43m[\u001b[49m\u001b[43moutput_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp/lib/python3.8/site-packages/pytesseract/pytesseract.py:426\u001b[0m, in \u001b[0;36mimage_to_string.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;124;03mReturns the result of a Tesseract OCR run on the provided image to string\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    421\u001b[0m args \u001b[38;5;241m=\u001b[39m [image, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtxt\u001b[39m\u001b[38;5;124m'\u001b[39m, lang, config, nice, timeout]\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    424\u001b[0m     Output\u001b[38;5;241m.\u001b[39mBYTES: \u001b[38;5;28;01mlambda\u001b[39;00m: run_and_get_output(\u001b[38;5;241m*\u001b[39m(args \u001b[38;5;241m+\u001b[39m [\u001b[38;5;28;01mTrue\u001b[39;00m])),\n\u001b[1;32m    425\u001b[0m     Output\u001b[38;5;241m.\u001b[39mDICT: \u001b[38;5;28;01mlambda\u001b[39;00m: {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m: run_and_get_output(\u001b[38;5;241m*\u001b[39margs)},\n\u001b[0;32m--> 426\u001b[0m     Output\u001b[38;5;241m.\u001b[39mSTRING: \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    427\u001b[0m }[output_type]()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp/lib/python3.8/site-packages/pytesseract/pytesseract.py:288\u001b[0m, in \u001b[0;36mrun_and_get_output\u001b[0;34m(image, extension, lang, config, nice, timeout, return_bytes)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m save(image) \u001b[38;5;28;01mas\u001b[39;00m (temp_name, input_filename):\n\u001b[1;32m    278\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_filename\u001b[39m\u001b[38;5;124m'\u001b[39m: input_filename,\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_filename_base\u001b[39m\u001b[38;5;124m'\u001b[39m: temp_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m'\u001b[39m: timeout,\n\u001b[1;32m    286\u001b[0m     }\n\u001b[0;32m--> 288\u001b[0m     \u001b[43mrun_tesseract\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_filename_base\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mextsep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mextension\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m output_file:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp/lib/python3.8/site-packages/pytesseract/pytesseract.py:260\u001b[0m, in \u001b[0;36mrun_tesseract\u001b[0;34m(input_filename, output_filename_base, extension, lang, config, nice, timeout)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 260\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m TesseractNotFoundError()\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m timeout_manager(proc, timeout) \u001b[38;5;28;01mas\u001b[39;00m error_string:\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mreturncode:\n",
      "\u001b[0;31mTesseractNotFoundError\u001b[0m: tesseract is not installed or it's not in your PATH. See README file for more information."
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from pytesseract import image_to_string\n",
    "\n",
    "\n",
    "YOUR_DEMO_DATA_PATH = \"data/\"  # please change your file path\n",
    "filename = YOUR_DEMO_DATA_PATH+'pdf-firth-text.png'\n",
    "text = image_to_string(Image.open(filename))\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sdKv1R92iQ-q"
   },
   "source": [
    "#### Unicode 标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nE0X28p_iQ-q",
    "outputId": "5505f6c9-ae58-406f-f868-813fab0cd053"
   },
   "outputs": [],
   "source": [
    "text = 'I feel really 😡. GOGOGO!! 💪💪💪  🤣🤣 ȀÆĎǦƓ'\n",
    "print(text)\n",
    "text2 = text.encode('utf-8') # encode the strings in bytes\n",
    "print(text2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gvXiND8KiQ-r",
    "outputId": "40c22da5-a6f1-4631-c3f5-6e77b37dda2f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I feel really . GOGOGO!!    ADG'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unicodedata\n",
    "unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQyvzlT1iQ-t"
   },
   "source": [
    "- 详细请查阅 [unicodedata documentation](https://docs.python.org/3/library/unicodedata.html) \n",
    "- 其他有用的库\n",
    "    - 拼写检查 (Spelling check): pyenchant, Microsoft REST API\n",
    "    - PDF:  PyPDF, PDFMiner\n",
    "    - OCR: pytesseract\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ddFBa9whiQ-t"
   },
   "source": [
    "### 文本清洗\n",
    "\n",
    "- 预备知识\n",
    "    - Sentence segmentation\n",
    "    - Word tokenization\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ce_hYOBiQ-t"
   },
   "source": [
    "#### 分段和标记化 (Segmentation and Tokenization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g0_4-fYhiQ-t",
    "outputId": "1806db13-61d2-4a42-8f89-72e22c9cfd05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Python is an interpreted, high-level and general-purpose programming language.\n",
      "['Python', 'is', 'an', 'interpreted', ',', 'high-level', 'and', 'general-purpose', 'programming', 'language', '.']\n",
      "Python's design philosophy emphasizes code readability with its notable use of significant whitespace.\n",
      "['Python', \"'s\", 'design', 'philosophy', 'emphasizes', 'code', 'readability', 'with', 'its', 'notable', 'use', 'of', 'significant', 'whitespace', '.']\n",
      "Its language constructs and object-oriented approach aim to help programmers write clear, logical code for small and large-scale projects.\n",
      "['Its', 'language', 'constructs', 'and', 'object-oriented', 'approach', 'aim', 'to', 'help', 'programmers', 'write', 'clear', ',', 'logical', 'code', 'for', 'small', 'and', 'large-scale', 'projects', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "text = '''\n",
    "Python is an interpreted, high-level and general-purpose programming language. Python's design philosophy emphasizes code readability with its notable use of significant whitespace. Its language constructs and object-oriented approach aim to help programmers write clear, logical code for small and large-scale projects.\n",
    "'''\n",
    "\n",
    "## sent segmentation\n",
    "sents = sent_tokenize(text)\n",
    "\n",
    "## word tokenization\n",
    "for sent in sents:\n",
    "    print(sent)\n",
    "    print(word_tokenize(sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qxX_eM6DiQ-u"
   },
   "source": [
    "- 经常使用的预处理 （preprocessing）\n",
    "    - 停用词 (Stopword) 移除\n",
    "    - Stemming 和lemmatization\n",
    "    - 数字或标点移除\n",
    "    - 大小写标准化\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TVrAuhfJiQ-u"
   },
   "source": [
    "#### 删除停用词、标点符号和数字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SD1S8lsZiQ-u",
    "outputId": "962624f2-e21b-4ef5-decb-3c3892de766d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mr.', 'John', \"O'Neil\", 'works', 'at', 'Wonderland', ',', 'located', 'at', '245', 'Goleta', 'Avenue', ',', 'CA.', ',', '74208', '.']\n",
      "Mr.\n",
      "John\n",
      "O'Neil\n",
      "works\n",
      "Wonderland\n",
      "located\n",
      "Goleta\n",
      "Avenue\n",
      "CA.\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "eng_stopwords = stopwords.words('english')\n",
    "\n",
    "text = \"Mr. John O'Neil works at Wonderland, located at 245 Goleta Avenue, CA., 74208.\"\n",
    "\n",
    "words = word_tokenize(text)\n",
    "\n",
    "print(words)\n",
    "\n",
    "# remove stopwords, punctuations, digits\n",
    "for w in words:\n",
    "    if w not in eng_stopwords and w not in punctuation and not w.isdigit():\n",
    "        print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m8BRzw57iQ-u"
   },
   "source": [
    "#### Stemming 和 lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-GoRYlcUiQ-u",
    "outputId": "98d2a94b-60ce-4b65-e877-db22b1cfe195"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['car', 'revolut', 'better']\n"
     ]
    }
   ],
   "source": [
    "## Stemming\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "words = ['cars','revolution', 'better']\n",
    "print([stemmer.stem(w) for w in words])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WiwUYRdTiQ-v",
    "outputId": "e2c09901-82ba-46df-f462-806f901e4003"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car\n",
      "revolution\n",
      "good\n"
     ]
    }
   ],
   "source": [
    "## Lemmatization\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "## Wordnet requires POS of words\n",
    "poss = ['n','n','a']\n",
    "\n",
    "for w,p in zip(words,poss):\n",
    "    print(lemmatizer.lemmatize(w, pos=p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oo-GlGYhiQ-v"
   },
   "source": [
    "- 和任务相关的预处理 (preprocessing)\n",
    "    - Unicode 标准化\n",
    "    - 语言检测 (Language detection)\n",
    "    - 混合编码 (Code mixing)\n",
    "    - 同音异形 (Transliteration) (e.g., using piyin for Chinese words in English-Chinese code-switching texts)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2oOQG_bbiQ-v"
   },
   "source": [
    "- 自动化标注 (Automatic annotations)\n",
    "    - 语法标记 (POS tagging)\n",
    "    - 解析 (Parsing)\n",
    "    - 命名实体识别 (Named Entity Recognition)\n",
    "    - 指代消解 (Coreference resolution)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dbfufLaciQ-v"
   },
   "source": [
    "### 预处理的重要提醒\n",
    "\n",
    "- 并不是所有的预处理过程都是必要的，要根据具体情况分析，预处理所带来的的好处和弊端\n",
    "- 这些步骤不是顺序的\n",
    "- 这些步骤取决于任务的\n",
    "- 预处理的目标\n",
    "    - 文本标准化 (Text Normalization)\n",
    "    - 文本单词化 (Text Tokenization)\n",
    "    - 文本增补和丰富 (Text Enrichment/Annotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DMbPXmUOiQ-v"
   },
   "source": [
    "## 特征工程 (Feature Engineering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xob6EYgsiQ-v"
   },
   "source": [
    "### 什么是特征工程 (feature engineering)?\n",
    "\n",
    "- 它是指将提取和预处理的文本输入机器学习算法的过程\n",
    "- 它旨在将文本的特征捕捉到一个数字向量中，该向量可以被ML算法理解。(Cf. *construct*, *operational definitions*, and *measurement* in experimental science)\n",
    "- 简言之，它涉及到如何有意义地定量表示文本, i.e., text representation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F15WIiBGiQ-w"
   },
   "source": [
    "### 传统机器学习算法的特征工程 \n",
    "\n",
    "- 基于词的频率表\n",
    "- 文字袋表示法 \n",
    "- 特定于域的词频列表 \n",
    "- 基于领域特定知识的手工特征 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Lr8MoHGiQ-w"
   },
   "source": [
    "### 深度学习的特征工程\n",
    "\n",
    "- DL直接将文本作为模型的输入\n",
    "- DL模型能够从文本中学习特征 (e.g., embeddings)\n",
    "- 其代价是，该模型往往难以解释\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vr3qBK09iQ-w"
   },
   "source": [
    "## 建模"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mi7Z_24AiQ-w"
   },
   "source": [
    "### 从简单到复杂\n",
    "\n",
    "- 从启发式或规则开始\n",
    "- 不同 ML 模型的实验\n",
    "    - 从启发式到特征\n",
    "    - 从手动注释到自动提取\n",
    "    - 特征重要性 (Feature importance/weights) \n",
    "- 找到最佳的模型\n",
    "    - Ensemble 和 stacking\n",
    "    - 重做 feature engineering\n",
    "    - 迁移学习 (Transfer learning)\n",
    "    - 重新应用启发式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6j3mLjs6iQ-w"
   },
   "source": [
    "## 评估 (Evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wL6pEOyMiQ-x"
   },
   "source": [
    "### 为什么要 evaluation?\n",
    "\n",
    "- 我们需要知道我们建立的模型有多好 \n",
    "- 与评估方法相关的因素 \n",
    "    - 建模方法 (Model building)\n",
    "    - 部署 (Deployment)\n",
    "    - 生产 (Production)\n",
    "- ML度量与业务度量 （ML metrics vs. Business metrics）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YD4RGO1biQ-x"
   },
   "source": [
    "### 内在评价与外在评价\n",
    "\n",
    "- 以垃圾邮件分类系统为例 Take spam-classification system as an example\n",
    "- 内在评价:\n",
    "    - 垃圾邮件分类/预测的精度和召回率\n",
    "- 外在评价:\n",
    "    - 用户在垃圾邮件上花费的时间\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EBPVYewLiQ-x"
   },
   "source": [
    "### 一般性原则\n",
    "\n",
    "- 在外部评估之前先进行内部评估。\n",
    "- 外部评估成本更高，因为它通常涉及人工智能团队以外的项目干系人\n",
    "- 只有当我们在内在评价中获得一致的好结果时，我们才应该进行外在评价\n",
    "- 内在的不良结果往往意味着外在的不良结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LArXgxVLiQ-x"
   },
   "source": [
    "### 通用的 Intrinsic Metrics\n",
    "\n",
    "- 评估指标选择原则 \n",
    "- 标签的数据类型 (ground truths)\n",
    "    - 二元 (Binary) (e.g., sentiment)\n",
    "    - 序型 (Ordinal) (e.g., informational retrieval)\n",
    "    - 分类 (Categorical) (e.g., POS tags)\n",
    "    - 文本 (Textual) (e.g., named entity, machine translation, text generation)\n",
    "- 自动与人工评估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NRtQF5YiiQ-x"
   },
   "source": [
    "## 后建模阶段 (Post-Modeling Phases)\n",
    "\n",
    "- 在生产环境中部署模型 (e.g., web service)\n",
    "- 定期监控系统性能 \n",
    "- 用新的数据更新系统"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
