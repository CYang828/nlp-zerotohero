{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hello，同学们，你掌握本节课的知识了吗？现在来实现一个简易的中文输入法吧！巩固一下知识。\n",
    "\n",
    "本节课的作业要求：\n",
    "\n",
    "+ 熟练掌握n-gram语言模型\n",
    "\n",
    "+ 认真阅读注释，对你做对该题至关重要\n",
    "\n",
    "+ 作业已经给出大部分程序实现代码，你只需要在`######## your code ~n line ########` 与 `######## your code end ########` 行之间根据提示补充完毕相应的代码即可。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据集：\n",
    "+ 我们使用一个中文新闻分类的数据集，大家可以通过这里来下载。[点击我下载](https://pan.baidu.com/s/1oTdl_Swo5z0mDdGxNa4bwg) 提取码:5hm5\n",
    "+ 数据集一共由三个文件组成，分别是`train.txt`、`dev.txt`、`test.txt`，共20万条，文件中每一行中由文本和其对应的类别id组成，两者之间使用`\\t`分开，这里只有前面的文本内容对本任务有用。\n",
    "+ 下载后解压缩，放在本作业notebook相同目录下即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.读取语料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载语料\n",
    "def load_corpus():\n",
    "    texts = []\n",
    "    base = './THUCNews/'\n",
    "    # os.listdir(base) 列出base目录下的所有文件名\n",
    "    files = os.listdir(base)\n",
    "    for name in files:\n",
    "        if not name.endswith('.txt'):\n",
    "            continue\n",
    "        with open(base + name, 'r', encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "            # 使用.split('\\t')分开标题与类别id\n",
    "            texts += [lin.strip().split('\\t')[0] for lin in lines]\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'一共200000条文本'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = load_corpus()\n",
    "'一共%s条文本' % len(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.为每条句子前后添加特殊标记\n",
    "\n",
    "为了让我们的N-gram语言模型能够对所有有限长的句子都赋予一个概率，我们面临一个小问题：怎么建模句子的结束？一种办法是我们有一个模型来建模句子的长度n，但是更加简单的办法是引入一个特殊的句子结束标签`</s>`来表示句子的结束。从生成模型的角度来说，我们先预测第一个词，然后用第一个词预测第二个词(假设是bigram)，然后用第二个词预测第三个词，……，直到遇到`</s>`，我们结束这个过程。这样的模型能够保证所有可能句子的概率加起来是1，也就是一个合法的概率分布。\n",
    "\n",
    "但是前面一个问题就是预测第一个词没有history，虽然我们记为$p(w_{1})$，但是它不是词$w_{1}$出现的概率，而是词$w_{1}$出现在第一个位置的概率！为了统一记号，我们引入一个特殊的句子开始标签`<s>`，这样记为$p(w_{1} \\vert <s>)$，它表示词$w_{1}$出现在`<s>`后的概率，也就是$w_{1}$出现在第一个位置的概率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题一：为每条语料前后添加特殊标记开头添加`<s>`结尾添加`</s>`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_both_ends(texts):\n",
    "    pad_texts = []\n",
    "    for text in texts:\n",
    "        text = list(text) # 拆分字符，这里按字力度实现语言模型，例子：中国留学生->['中','国','留','学','生']\n",
    "        # 提示：list().insert(index, 'something') 是为列表中index位置添加一个元素；\n",
    "        # list().append()是在列表最后追加一个元素\n",
    "        ######## your code ~2 line ######## \n",
    "        text.insert(0, '<s>')  \n",
    "        text.append('</s>')\n",
    "        ######## your code end ########\n",
    "        pad_texts.append(text)\n",
    "    return pad_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " '6',\n",
       " '0',\n",
       " '年',\n",
       " '铁',\n",
       " '树',\n",
       " '开',\n",
       " '花',\n",
       " '形',\n",
       " '状',\n",
       " '似',\n",
       " '玉',\n",
       " '米',\n",
       " '芯',\n",
       " '(',\n",
       " '组',\n",
       " '图',\n",
       " ')',\n",
       " '</s>']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_texts = pad_both_ends(texts)\n",
    "pad_texts[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.统计语料中字的频率，生成字与id、id与字的映射关系"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题二：统计语料中字的频率；字与id的映射。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(pad_texts):\n",
    "    # word2freq：key是字，value是该字对应的出现频率。\n",
    "    word2freq = {}\n",
    "    for pad_text in pad_texts:\n",
    "        for w in pad_text:\n",
    "            # 提示：判断当前字（w）是否在word2freq的keys中存在，不存在就添加w，对应的value为1\n",
    "            # 存在，把key（w）对应的value加1\n",
    "            ######## your code ~4 line ######## \n",
    "            if w not in word2freq.keys():\n",
    "                word2freq[w] = 1\n",
    "            else:\n",
    "                word2freq[w] += 1\n",
    "            ######## your code end ######## \n",
    "    # word2id：key是字，value是该字对应的id。\n",
    "    word2id = {}\n",
    "    for key, _ in word2freq.items():\n",
    "        # 提示：word2id中value的id从0开始增加\n",
    "        # 每次设置key的值为word2id的长度\n",
    "        ######## your code ~1 line ######## \n",
    "        word2id[key] = len(word2id)\n",
    "        ######## your code end ######## \n",
    "    # id2word: list中每个元素是字，其对应的索引是字的id\n",
    "    id2word = []\n",
    "    for word, _ in word2id.items():\n",
    "        id2word.append(word)\n",
    "    return word2freq, word2id, id2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab2freq, word2id, id2word = build_vocab(pad_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.创建转移矩阵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题三：定位共现词的坐标，把对应坐标上的数值+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_matrix(pad_texts, word2id):\n",
    "    # 创建一个全零的矩阵，矩阵位置(i,j)对应是，word2id中id为i和id为j的两个字在语料中同时出现了多少次，区分前后关系，i字在前j字在后\n",
    "    matrix = np.zeros((len(word2id), len(word2id)))\n",
    "    for pad_text in pad_texts:\n",
    "        # 计算句子长度\n",
    "        seq_len = len(pad_text)\n",
    "        for i in range(seq_len - 1):\n",
    "            # 2-gram中的前后字\n",
    "            pre_word = pad_text[i]\n",
    "            next_word = pad_text[i + 1]\n",
    "            # 前后字在字典中的id\n",
    "            # word2id 是字与id的对应关系\n",
    "            ######## your code ~2 line ######## \n",
    "            pre_id = word2id[pre_word]\n",
    "            next_id = word2id[next_word]\n",
    "            ######## your code end ######## \n",
    "            # 设置matrix对应的位置数值+1\n",
    "            ######## your code ~1 line ######## \n",
    "            matrix[pre_id][next_id] += 1\n",
    "            ######## your code end ######## \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4803, 4803)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = transfer_matrix(pad_texts, word2id)\n",
    "matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.预测下一个字\n",
    "\n",
    "提示：该部分你没有看到任何关于条件概率的计算代码。我们是根据给出的某个字（$w_{i}$），去预测下一个最大可能出现的字（$w_{i+1}$），根据语言模型计算公式：\n",
    "\n",
    "$P(w_{i+1}|w_{i})=$ $count(w_{i}, w_{i+1}) \\over count(w_{i})$，这里$w_{i}$是已知的，$w_{i+1}$是未知的，$w_{i+1}$的取值可能是词表中任意一个，我们只需要找出那个与$w_{i}$共同出现的次数最多的$w_{i+1}$即可。（在实现的过程中我们设置了个topk的参数，即找出最有可能出现的前k个）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题四：根据matrix矩阵，统计没有在某个字后面出现过的字的个数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_input(word, matrix, word2id, id2word):\n",
    "    # topk 给定前一个字，预测下面最有可能出现的topk个字\n",
    "    topk = 10\n",
    "    # 获取word对应的id\n",
    "    try:\n",
    "        word_id = word2id[word]\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return 'oov'\n",
    "    # 取出word对应matrix中的那一行数据\n",
    "    row = matrix[word_id]\n",
    "    # 计算字典中有多少字从来没有出现在word之后\n",
    "    # 提示：row中为0的元素对应的索引，都是没有出现在word之后的字的id，可以把等于0的数量进行累加\n",
    "    ######## your code ~1 line ######## \n",
    "    un_appare = (row == 0.0).sum()\n",
    "    ######## your code end ######## \n",
    "    # 函数argsort()把一个array向量按照元素从小到大排列，并返回排序前对应的索引id。\n",
    "    # 例子np.array([2, 5, 2, 1, 0]).argsort()，返回的是[4 3 0 2 1]，最小的元素是0，对应的位置索引id为4\n",
    "    # [::-1]把一个向量反转。例子：[1,2,3][::,-1]->[3,2,1]\n",
    "    # 出现在一个字之后的字是有限个的，有可能出现小于topk的情况，所以这里使用[:-un_appare]截取掉没有出现在word之后字的id\n",
    "    topk_word_id = matrix[word_id].argsort()[::-1][:-un_appare][:topk]\n",
    "    return {i: id2word[id] for i, id in enumerate(topk_word_id)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = input(\"请输入:\")\n",
    "while True:\n",
    "    res = next_input(word[-1], matrix, word2id, id2word)\n",
    "    if res == 'oov':\n",
    "        word = word[:-1]\n",
    "        word += input(\"你输入的字不存在，请重新输入:\")\n",
    "        continue\n",
    "    print(res)\n",
    "    id = input(\"请选择下一个词，输入对应的id，如果提供的列表中不存在接下来你想要的输入，请输入-1。\")\n",
    "    if int(id) != -1:\n",
    "        next_word = res[int(id)]\n",
    "        if next_word == \"</s>\":\n",
    "            break\n",
    "    else:\n",
    "        next_word = input(\"请输入你想要的字：\")\n",
    "        if next_word == \"</s>\":\n",
    "            break\n",
    "    word += next_word\n",
    "    print(word)\n",
    "    print('-'*60)\n",
    "print(\"你输入的搜索内容是:{}\".format(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_core",
   "language": "python",
   "name": "nlp_core"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
