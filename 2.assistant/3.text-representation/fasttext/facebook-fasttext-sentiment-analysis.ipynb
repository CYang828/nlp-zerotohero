{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用 Facebook fastText 工具对数据集进行情感分析\n",
    "\n",
    "使用1-5的评分，任务是预测评论的评分。使用fastText的监督学习方法，希望模型可以将评论分类为5个评分之一。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 安装 fasttext\n",
    "\n",
    "从 git 下载 fasttext 并使用 pip 安装。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/facebookresearch/fastText/archive/v0.9.2.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip v0.9.2.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd fastText-0.9.2 && pip install ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 清理数据\n",
    "\n",
    "作为使用不同类型数据集的 fasttext，与 TF 或 Keras 不同。Fasttext 使用基于文本的文件数据集，标签与数据位于同一行。标签必须以`__label__<label word>` 开头，因此需要更改当前数据集。\n",
    "    \n",
    "当然，另一个原因是当前数据集仍然处于“脏”状态，带有混合大小写字符串，尚未进行流形化或词干化，还包含新行和其他内容。\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"The cleaning supply\"\n",
    "import re\n",
    "import string\n",
    "\n",
    "# \"NLP Supply\"\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "打开文件、主要训练数据以及测试数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../input/student-shopee-code-league-sentiment-analysis/train.csv\")\n",
    "test = pd.read_csv(\"../input/student-shopee-code-league-sentiment-analysis/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "检查两个数据集的内部"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用于预处理文本的 Cleaner 函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the lemmarizer and stemmer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "englishStemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "\n",
    "def clean_text(x):\n",
    "    # Remove zero width space from the string and lower it\n",
    "    temp_text = x.lower().replace(\"\\u200b\", \"\")\n",
    "    # Remove punctuation of the string\n",
    "    temp_text = temp_text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    # Remove new line from string\n",
    "    temp_text = temp_text.replace(\"\\n\", \"\")\n",
    "    # Remove double space or more\n",
    "    temp_text = re.sub(\" +\", \" \", temp_text).strip()\n",
    "    # Tokenized the text\n",
    "    temp_text = nltk.word_tokenize(temp_text)\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "    filtered_word = []\n",
    "\n",
    "    for word in temp_text:\n",
    "        # Lemmanize and stem word\n",
    "        lemma_word = wordnet_lemmatizer.lemmatize(word)\n",
    "        stemmed_word = englishStemmer.stem(lemma_word)\n",
    "\n",
    "        # Do not add stop words into the the final cleaned sentence\n",
    "        if stemmed_word in stop_words:\n",
    "            continue\n",
    "        else:\n",
    "            filtered_word.append(stemmed_word)\n",
    "\n",
    "    return \" \".join(filtered_word).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean all of the review in training, and test\n",
    "train[\"review\"] = train[\"review\"].apply(clean_text)\n",
    "test[\"review\"] = test[\"review\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将训练和验证数据拆分为 2 个不同的数据帧。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAL_PERCENTAGE = 0.2\n",
    "N_VAL = int(len(train) * VAL_PERCENTAGE)\n",
    "\n",
    "# Shuffle train DataFrame also reset the shuffled index\n",
    "train = train.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Set validation DataFrame as having the first N_VAL row\n",
    "val_data = train[:N_VAL]\n",
    "\n",
    "# Set train DataFrame as the rest\n",
    "train_data = train[N_VAL:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 转换数据集\n",
    "\n",
    "创建函数将当前数据集行转换为字符串，该字符串是fastText的训练数据中的行。\n",
    "它看起来像 `__label_<1-5><review>`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_file_path = \"./review.val\"\n",
    "training_file_path = \"./review.train\"\n",
    "\n",
    "\n",
    "def append_fasttext_dataset(row, file_writer):\n",
    "    def convert_row_to_dataset_string(row):\n",
    "        return \"__label__\" + str(row[\"rating\"]) + \" \" + row[\"review\"]\n",
    "\n",
    "    file_writer.write(convert_row_to_dataset_string(row) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "写入验证和训练文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation file\n",
    "with open(validation_file_path, \"a+\") as writer:\n",
    "    val_data.apply(lambda x: append_fasttext_dataset(x, writer), axis=1)\n",
    "\n",
    "# Training file\n",
    "with open(training_file_path, \"a+\") as writer:\n",
    "    train_data.apply(lambda x: append_fasttext_dataset(x, writer), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看数据集，看看是否存在偏差或任何其他差异。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at number of label (1-5) of the training data\n",
    "train_data[\"rating\"].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at number of label (1-5) of the validation data\n",
    "val_data[\"rating\"].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如条形图所示，数据偏向较高的评级。这对于评论数据来说是常见的，因为大多数人可能只是在他们的购买上留下了一个好分数，除非发生了小事情，它将是4星，有时是3星。但如果这是一次重大的采购事件，人们只会给卖家一颗星的评价。\n",
    "\n",
    "这对培训来说是一件坏事，因为模型（可能）更可能在审查中给出比实际情况更高的评级。使用上采样方法，通过将少数类复制到与多数类相同或几乎相同的级别，可以解决数据集的这个问题。这样做的问题是，我们将冒风险，过度拟合模型，重复审查。特别是前面所示的巨大差异。\n",
    "\n",
    "现在，我们将“按原样”运行它，看看会发生什么。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用 fastText 进行训练\n",
    "\n",
    "现在，实际制作模型的有趣部分将对我们的数据进行分类。我们将使用fastText的监督训练方法来完成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义训练阶段的参数，\n",
    "\n",
    "- **lr** : 训练的学习率\n",
    "- **epoch** : 训练将对数据进行多少次检查\n",
    "- **wordNgrams** : 给定文本样本中最大 n 个单词的连续序列\n",
    "- **dim** : 词向量的维数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params = {\"lr\": 0.01, \"epoch\": 15, \"wordNgrams\": 2, \"dim\": 20, \"verbose\": 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，使用适当的输入文件构建我们将使用的fasttext模型，然后模型将使用我们的参数自动使用该文件进行训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.train_supervised(input=training_file_path, **hyper_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "检查模型本身的性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model accuracy and accuracy of the validation\n",
    "result = model.test(training_file_path)\n",
    "validation = model.test(validation_file_path)\n",
    "\n",
    "print(\"Result : \", result)\n",
    "print(\"Validation : \", validation)\n",
    "\n",
    "# Plot the result\n",
    "accuracy_data = [result[1], validation[1]]\n",
    "labels = [\"Model Accuracy\", \"Validation Accuracy\"]\n",
    "\n",
    "plt.title(\"Model accuracy\")\n",
    "plt.bar(labels, accuracy_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "该模型的准确率在50%以上，验证数据也显示了这一点（稍微有点差异是可以的），但让我们看看如何实际改进它。也许首先我们需要查看模型的混淆矩阵，看看它是如何处理标签的，以及哪个标签实际上对它影响最大。\n",
    "\n",
    "为了对数据帧中使用的标签进行预测和转换，我们将创建一个函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predicted_rating(x, model):\n",
    "    return int(model.predict(x)[0][0].split(\"__label__\")[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在获得所有验证数据的预测结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data[\"predicted\"] = val_data[\"review\"].apply(\n",
    "    lambda x: get_predicted_rating(x, model)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后使用 sklearn 工具制作混淆矩阵，以更轻松地解释数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_labels = [1, 2, 3, 4, 5]\n",
    "confusion_matrix_data = confusion_matrix(\n",
    "    val_data[\"rating\"], val_data[\"predicted\"], labels=confusion_labels\n",
    ")\n",
    "normalised_confusion_matrix = (\n",
    "    confusion_matrix_data.astype(\"float\")\n",
    "    / confusion_matrix_data.sum(axis=1)[:, np.newaxis]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the normalised confusion matrix\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(normalised_confusion_matrix, annot=True, ax=ax, fmt=\".2f\")\n",
    "\n",
    "ax.set_title(\"Normalized Confusion Matrix\")\n",
    "\n",
    "ax.set_xlabel(\"Predicted labels\")\n",
    "ax.set_ylabel(\"True labels\")\n",
    "\n",
    "ax.xaxis.set_ticklabels(confusion_labels)\n",
    "ax.yaxis.set_ticklabels(confusion_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看来我们的预测是错误的！大多数问题存在于等级4和等级5之间的假阳性和假阴性之间。等级3和等级2之间也存在假阳性。所有这些标签的值均为0.4-ish，这意味着几乎一半的标签被错误地标记为其相应的相邻等级。这可能意味着评级4和5、5和4，以及评级3和2具有密切相关的趋势，或密切正或负。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 探索改进\n",
    "在本节中，很少有人尝试使用不同的方法来改进当前模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 更多的 Epoch\n",
    "通过将模型更多地暴露在数据中，模型可能会更好地“学习”模式，并更好地区分数据中的模式。\n",
    "\n",
    "首先，让我们确定执行此操作的参数。让我们试着再加一点，也许10。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params_25_epoch = {\n",
    "    \"lr\": 0.01,\n",
    "    \"epoch\": 25,\n",
    "    \"wordNgrams\": 2,\n",
    "    \"dim\": 20,\n",
    "    \"verbose\": 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_25_epoch = fasttext.train_supervised(\n",
    "    input=training_file_path, **hyper_params_25_epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model accuracy and accuracy of the validation\n",
    "result = model_25_epoch.test(training_file_path)\n",
    "validation = model_25_epoch.test(validation_file_path)\n",
    "\n",
    "print(\"Result : \", result)\n",
    "print(\"Validation : \", validation)\n",
    "\n",
    "# Plot the result\n",
    "accuracy_data = [result[1], validation[1]]\n",
    "labels = [\"Model Accuracy\", \"Validation Accuracy\"]\n",
    "\n",
    "plt.title(\"Model accuracy with 25 epoch\")\n",
    "plt.bar(labels, accuracy_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型精度本身（使用训练数据）与验证数据精度之间的差异似乎比以前有更大的差距。这可能意味着模型正在开始或已经过拟合，因为它非常了解训练数据，但不知道它从未见过的数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 更大的 Learning Rate\n",
    "\n",
    "通过对预测误差率做出更大的响应，模型可能会更快地找到“谷”，并最终使其更准确。\n",
    "\n",
    "现在，使超参数具有更高的学习率。我可能会选择，0.6或什么。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params_bigger_lr = {\n",
    "    \"lr\": 0.6,\n",
    "    \"epoch\": 15,\n",
    "    \"wordNgrams\": 2,\n",
    "    \"dim\": 20,\n",
    "    \"verbose\": 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bigger_lr = fasttext.train_supervised(\n",
    "    input=training_file_path, **hyper_params_bigger_lr\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model accuracy and accuracy of the validation\n",
    "result = model_bigger_lr.test(training_file_path)\n",
    "validation = model_bigger_lr.test(validation_file_path)\n",
    "\n",
    "print(\"Result : \", result)\n",
    "print(\"Validation : \", validation)\n",
    "\n",
    "# Plot the result\n",
    "accuracy_data = [result[1], validation[1]]\n",
    "labels = [\"Model Accuracy\", \"Validation Accuracy\"]\n",
    "\n",
    "plt.title(\"Model accuracy with learning rate 0.6\")\n",
    "plt.bar(labels, accuracy_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看起来使用更高的学习率也没有帮助，因为训练数据和验证数据的差异越来越大，显示出过度拟合。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autotuning\n",
    "\n",
    "尝试使用作为参数提供的验证数据使模型实际改进自身。\n",
    "\n",
    "现在，为它创建参数。通过传递验证文件，模型将使用该文件作为模型的优化参考。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params_autotuning = {\n",
    "    \"lr\": 0.06,\n",
    "    \"epoch\": 20,\n",
    "    \"wordNgrams\": 2,\n",
    "    \"dim\": 20,\n",
    "    \"verbose\": 1,\n",
    "    \"autotuneValidationFile\": validation_file_path,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autotuning = fasttext.train_supervised(\n",
    "    input=training_file_path, **hyper_params_autotuning\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model accuracy and accuracy of the validation\n",
    "result = model_autotuning.test(training_file_path)\n",
    "validation = model_autotuning.test(validation_file_path)\n",
    "\n",
    "print(\"Result : \", result)\n",
    "print(\"Validation : \", validation)\n",
    "\n",
    "# Plot the result\n",
    "accuracy_data = [result[1], validation[1]]\n",
    "labels = [\"Model Accuracy\", \"Validation Accuracy\"]\n",
    "\n",
    "plt.title(\"Model accuracy with autotuning\")\n",
    "plt.bar(labels, accuracy_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data[\"predicted\"] = val_data[\"review\"].apply(\n",
    "    lambda x: get_predicted_rating(x, model_autotuning)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_labels = [1, 2, 3, 4, 5]\n",
    "confusion_matrix_data = confusion_matrix(\n",
    "    val_data[\"rating\"], val_data[\"predicted\"], labels=confusion_labels\n",
    ")\n",
    "normalised_confusion_matrix = (\n",
    "    confusion_matrix_data.astype(\"float\")\n",
    "    / confusion_matrix_data.sum(axis=1)[:, np.newaxis]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the normalised confusion matrix\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(normalised_confusion_matrix, annot=True, ax=ax, fmt=\".2f\")\n",
    "\n",
    "ax.set_title(\"Normalized Confusion Matrix (Autotuning)\")\n",
    "\n",
    "ax.set_xlabel(\"Predicted labels\")\n",
    "ax.set_ylabel(\"True labels\")\n",
    "\n",
    "ax.xaxis.set_ticklabels(confusion_labels)\n",
    "ax.yaxis.set_ticklabels(confusion_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自动调谐的使用似乎令人惊讶，在没有太多过度拟合的情况下达到了更高的精度，尽管在混乱矩阵上，一切都像以前一样，没有任何变化。在autotune函数中，我们还可以更改一些指标，例如优化某个标签的f1分数。\n",
    "\n",
    "这就是我要做的。让我们看看在优化 `__label__4` 的f1分数时使用聚焦指标会发生什么。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params_autotuning_metrics = {\n",
    "    \"lr\": 0.1,\n",
    "    \"epoch\": 20,\n",
    "    \"wordNgrams\": 2,\n",
    "    \"dim\": 50,\n",
    "    \"verbose\": 2,\n",
    "    \"autotuneValidationFile\": validation_file_path,\n",
    "    \"autotuneMetric\": \"f1:__label__4\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autotuning_metrics = fasttext.train_supervised(\n",
    "    input=training_file_path, **hyper_params_autotuning_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model accuracy and accuracy of the validation\n",
    "result = model_autotuning_metrics.test(training_file_path)\n",
    "validation = model_autotuning_metrics.test(validation_file_path)\n",
    "\n",
    "print(\"Result : \", result)\n",
    "print(\"Validation : \", validation)\n",
    "\n",
    "# Plot the result\n",
    "accuracy_data = [result[1], validation[1]]\n",
    "labels = [\"Model Accuracy\", \"Validation Accuracy\"]\n",
    "\n",
    "plt.title(\"Model accuracy with autotuning\")\n",
    "plt.bar(labels, accuracy_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data[\"predicted\"] = val_data[\"review\"].apply(\n",
    "    lambda x: get_predicted_rating(x, model_autotuning_metrics)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_labels = [1, 2, 3, 4, 5]\n",
    "confusion_matrix_data = confusion_matrix(\n",
    "    val_data[\"rating\"], val_data[\"predicted\"], labels=confusion_labels\n",
    ")\n",
    "normalised_confusion_matrix = (\n",
    "    confusion_matrix_data.astype(\"float\")\n",
    "    / confusion_matrix_data.sum(axis=1)[:, np.newaxis]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the normalised confusion matrix\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(normalised_confusion_matrix, annot=True, ax=ax, fmt=\".2f\")\n",
    "\n",
    "ax.set_title(\"Normalized Confusion Matrix (Autotuning Metrics f1:__label__4)\")\n",
    "\n",
    "ax.set_xlabel(\"Predicted labels\")\n",
    "ax.set_ylabel(\"True labels\")\n",
    "\n",
    "ax.xaxis.set_ticklabels(confusion_labels)\n",
    "ax.yaxis.set_ticklabels(confusion_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按照预期进行度量的结果是，评级4和5之间的混淆已经减少，尽管评级5和4之间的混淆正在增加。另一个未预料到但受欢迎的影响是评级2和3的混淆率较低。\n",
    "\n",
    "现在，如果重点放在评级5上呢。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params_autotuning_metrics_5 = {\n",
    "    \"lr\": 0.1,\n",
    "    \"epoch\": 20,\n",
    "    \"wordNgrams\": 2,\n",
    "    \"dim\": 50,\n",
    "    \"verbose\": 2,\n",
    "    \"autotuneValidationFile\": validation_file_path,\n",
    "    \"autotuneMetric\": \"f1:__label__5\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autotuning_metrics_5 = fasttext.train_supervised(\n",
    "    input=training_file_path, **hyper_params_autotuning_metrics_5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model accuracy and accuracy of the validation\n",
    "result = model_autotuning_metrics_5.test(training_file_path)\n",
    "validation = model_autotuning_metrics_5.test(validation_file_path)\n",
    "\n",
    "print(\"Result : \", result)\n",
    "print(\"Validation : \", validation)\n",
    "\n",
    "# Plot the result\n",
    "accuracy_data = [result[1], validation[1]]\n",
    "labels = [\"Model Accuracy\", \"Validation Accuracy\"]\n",
    "\n",
    "plt.title(\"Model accuracy with autotuning metrics\")\n",
    "plt.bar(labels, accuracy_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data[\"predicted\"] = val_data[\"review\"].apply(\n",
    "    lambda x: get_predicted_rating(x, model_autotuning_metrics_5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_labels = [1, 2, 3, 4, 5]\n",
    "confusion_matrix_data = confusion_matrix(\n",
    "    val_data[\"rating\"], val_data[\"predicted\"], labels=confusion_labels\n",
    ")\n",
    "normalised_confusion_matrix = (\n",
    "    confusion_matrix_data.astype(\"float\")\n",
    "    / confusion_matrix_data.sum(axis=1)[:, np.newaxis]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the normalised confusion matrix\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(normalised_confusion_matrix, annot=True, ax=ax, fmt=\".2f\")\n",
    "\n",
    "ax.set_title(\"Normalized Confusion Matrix (Autotuning Metrics f1:__label__5)\")\n",
    "\n",
    "ax.set_xlabel(\"Predicted labels\")\n",
    "ax.set_ylabel(\"True labels\")\n",
    "\n",
    "ax.xaxis.set_ticklabels(confusion_labels)\n",
    "ax.yaxis.set_ticklabels(confusion_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这不会产生比使用标签5的方法更好的混淆矩阵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提交文件\n",
    "按照预期的样本提交格式，制作提交给kaggle的文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = test.copy()\n",
    "submission[\"rating\"] = submission[\"review\"].apply(\n",
    "    lambda x: get_predicted_rating(x, model_autotuning_metrics)\n",
    ")\n",
    "\n",
    "del submission[\"review\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看预测结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将提交文件保存到csv中，csv文件中没有索引。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
